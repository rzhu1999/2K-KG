


const factory = require('@graphy/core.data.factory');
const writable = require('@graphy/core.class.writable');

const RT_PREFIXED_NAME_NAMESPACE_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?)?$/u;
const N_MAX_STRING_BUFFER = 1 << 12;



class TriG_Writer extends writable {
	constructor(gc_writer={}) {
		super(gc_writer);

		let {
			prefixes: h_prefixes={},
			indent: s_indent='\t',
			tokens: gc_tokens=null,
			collections: gc_collections=null,
			debug: b_debug=false,
		} = gc_writer;

		Object.assign(this, {
			indent: s_indent,
			debug: b_debug,
		});

		let s_graph_token = '';

			// token config
		if(gc_tokens) {
				// 'graph' token
			if(gc_tokens.graph) {
				let z_token = gc_tokens.graph;

					// boolean true
				if(true === z_token) {
					s_graph_token = 'GRAPH ';
				}
					// invalid type
				else if('string' !== typeof z_token) {
					throw new TypeError(`Invalid argument type given for 'graph' token: ${z_token}`);
				}
					// invalid token string
				else if(!/^graph$/i.test(z_token)) {
					throw new Error(`Graph token must equal case-insensitive "GRAPH"; found: "${z_token}"`);
				}
					// valid graph token; append space
				else {
					s_graph_token = z_token+' ';
				}
			}
		}

			// set graph token
		this.graph_token = s_graph_token;



		// custom collection keys
		if(gc_collections) {
			// serialize collection object
			this.collection_object = function(a_collection, n_nest_level) {
				// transcode collection object
				let hc2_transcoded = this.transcode_collection(a_collection);

				// serialize object
				return this.objects(hc2_transcoded, n_nest_level);
			};
		}

		// serialize initial prefix mappings
		let s_prefixes = '';
		try {
			// each user-defined prefix
			for(let s_prefix_id in h_prefixes) {
				// invalid prefix id
				if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
					throw new Error(`Invlalid prefix id for application/trig RDF serialization format: '${s_prefix_id}'`);
				}

				// append to string
				s_prefixes += `@prefix ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()} .\n`;
			}
		}
		// serialization error
		catch(e_serialize) {
			setTimeout(() => {
				this.emit('error', e_serialize);
			}, 0);
		}

		// push prefixes
		if(s_prefixes) this.push(s_prefixes);
	}

	// serialize prefixes
	serialize_prefixes(h_prefixes) {
		// build prefixes string
		let s_prefixes = (2 === this.state)? '\n\n': '';

		// update state
		this.state = 0;

		// each user-defined prefix
		for(let s_prefix_id in h_prefixes) {
			// invalid prefix id
			if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
				throw new Error(`Invlalid prefix id for application/trig RDF serialization format: '${s_prefix_id}'`);
			}

			// append to string
			s_prefixes += `@prefix ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()} .\n`;

			// set prefix
			this.prefixes[s_prefix_id] = h_prefixes[s_prefix_id];
		}

		// return prefix string
		return s_prefixes;
	}



		// serialize c3 hash
	serialize_c3(hc3_triples) {
		let {
			prefixes: h_prefixes,
			indent: s_indent,

		} = this;
	// break line if non-data state
		let s_write = 2 !== this.state? '\n': '';
	// update state
		this.state = 2;

			// triple delimiter
		let s_delim_triples = '';
		// each subject
		for(let sc1_subject in hc3_triples) {
				// directive
			if('`' === sc1_subject[0]) {
				s_write += s_delim_triples+this.directive(sc1_subject, hc3_triples[sc1_subject]);
				// do not break next line
				s_delim_triples = '';
				continue;
			}
			// position before subject
			let i_triples = s_write.length;
			// serialize subject
			s_write += s_delim_triples+factory.c1_node(sc1_subject, h_prefixes).terse(h_prefixes)+' ';
			// pair indent & terminator
			let s_indent_pairs = '';
			let s_term_pairs = '';
			// ref pairs
			let hc2_pairs = hc3_triples[sc1_subject];
			// position before pairs
			let i_pairs = s_write.length;
			// were objects written?
			let b_empty = true;
			// each predicate
			for(let sc1_predicate in hc2_pairs) {
					// directive
				if('`' === sc1_predicate[0]) {
						// break line
					s_write += (s_indent_pairs? s_term_pairs: '\n')+s_indent;
					// serialize directive
					s_write += this.directive(sc1_predicate, hc2_pairs[sc1_predicate]);
					// pair already terminated
					s_term_pairs = '';
					// indent next pair
					s_indent_pairs = s_indent;
					continue;
				}
				// ref objects
				let z_objects = hc2_pairs[sc1_predicate];
				// serialize objects
				let st_objects = this.objects(z_objects);
				// no objects; skip pair
				if(!st_objects) continue;
				// not empty
				b_empty = false;
				// cannot use blank node in predicate position
				if('_' === sc1_predicate[0] && ':' === sc1_predicate[1]) {
					throw new Error(`Cannot use blank node in predicate position of c3 hash; subject:'${sc1_subject}', predicate:'${sc1_predicate}'`);
				}
				// create predicate
				let kt_predicate = factory.c1_named_node(sc1_predicate, h_prefixes);
				// tersify rdf:type
				let st_predicate = kt_predicate.isRdfTypeAlias? 'a': kt_predicate.terse(h_prefixes);
				// serialize predicate and object(s)
				s_write += s_term_pairs+s_indent_pairs+st_predicate+' '+st_objects;
				// update state
				this.state = 2;
				// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
				// terminate next pair
				s_term_pairs = ' ;\n';
				// indent next pair
				s_indent_pairs = s_indent;
			}
			// empty triples; cut out
			if(b_empty) {
				s_write = s_write.slice(0, i_triples)+s_write.slice(i_pairs);
				continue;
			}
			// delimit triple(s)
			s_delim_triples = '\n';
			// close triple
			s_write += `${s_term_pairs? ' ': s_indent_pairs}.\n`; //
		}

		s_write += '\n';

		return s_write;
	}


		// serialize c4 hash
	serialize_c4(hc4_quads) {
		let {
			prefixes: h_prefixes,
			indent: s_indent,

		} = this;
	// break line if non-data state
		let s_write = 2 !== this.state? '\n': '';
	// update state
		this.state = 2;
				// graph token
		let s_graph_token = this.graph_token;

			// each graph
		for(let sc1_graph in hc4_quads) {
				// directive
			if('`' === sc1_graph[0]) {
				s_write += this.directive(sc1_graph, hc4_quads[sc1_graph]);
				continue;
			}

				// serialize open graph
			let st_graph = factory.c1_node(sc1_graph, h_prefixes).terse(h_prefixes);
			s_write += s_graph_token+(st_graph? st_graph+' ': '')+'{\n';

				// update state
			this.state = 2;

				// ref triples
			let hc3_triples = hc4_quads[sc1_graph];

			// triple delimiter
			let s_delim_triples = '';
		// each subject
			for(let sc1_subject in hc3_triples) {
				// directive
				if('`' === sc1_subject[0]) {
					s_write += s_delim_triples+s_indent+this.directive(sc1_subject, hc3_triples[sc1_subject]);
				// do not break next line
					s_delim_triples = '';
					continue;
				}
			// position before subject
				let i_triples = s_write.length;
			// serialize subject
				s_write += s_delim_triples+s_indent+factory.c1_node(sc1_subject, h_prefixes).terse(h_prefixes)+' ';
			// pair indent & terminator
				let s_indent_pairs = '';
				let s_term_pairs = '';
			// ref pairs
				let hc2_pairs = hc3_triples[sc1_subject];
			// position before pairs
				let i_pairs = s_write.length;
			// were objects written?
				let b_empty = true;
			// each predicate
				for(let sc1_predicate in hc2_pairs) {
					// directive
					if('`' === sc1_predicate[0]) {
						// break line
						s_write += (s_indent_pairs? s_term_pairs: '\n')+s_indent+s_indent;
					// serialize directive
						s_write += this.directive(sc1_predicate, hc2_pairs[sc1_predicate]);
					// pair already terminated
						s_term_pairs = '';
					// indent next pair
						s_indent_pairs = s_indent+s_indent;
						continue;
					}
				// ref objects
					let z_objects = hc2_pairs[sc1_predicate];
				// serialize objects
					let st_objects = this.objects(z_objects);
				// no objects; skip pair
					if(!st_objects) continue;
				// not empty
					b_empty = false;
				// cannot use blank node in predicate position
					if('_' === sc1_predicate[0] && ':' === sc1_predicate[1]) {
						throw new Error(`Cannot use blank node in predicate position of c4 hash; graph:'${sc1_graph}', subject:'${sc1_subject}', predicate:'${sc1_predicate}'`);
					}
				// create predicate
					let kt_predicate = factory.c1_named_node(sc1_predicate, h_prefixes);
				// tersify rdf:type
					let st_predicate = kt_predicate.isRdfTypeAlias? 'a': kt_predicate.terse(h_prefixes);
				// serialize predicate and object(s)
					s_write += s_term_pairs+s_indent_pairs+st_predicate+' '+st_objects;
				// update state
					this.state = 2;
				// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
				// terminate next pair
					s_term_pairs = ' ;\n';
				// indent next pair
					s_indent_pairs = s_indent+s_indent;
				}
			// empty triples; cut out
				if(b_empty) {
					s_write = s_write.slice(0, i_triples)+s_write.slice(i_pairs);
					continue;
				}
			// delimit triple(s)
				s_delim_triples = '\n';
			// close triple
				s_write += `${s_term_pairs? ' ': s_indent_pairs}.\n`; // \n
			}
					// close graph
			s_write += '}\n\n';
		}

		return s_write;
	}

		// write objects
	objects(z_objects, n_nest_level=1) {
		let {
			prefixes: h_prefixes,
			indent: s_indent,
			coercions: hm_coercions,
		} = this;

		// deduce object value type
		switch(typeof z_objects) {
			// concise-term string
			case 'string': return factory.c1(z_objects, h_prefixes).terse(h_prefixes);

			// numeric type
			case 'number': return factory.number(z_objects).terse(h_prefixes);

			// boolean type
			case 'boolean': return factory.boolean(z_objects).terse(h_prefixes);

			// object
			case 'object': {
				// null; reject
				if(null === z_objects) throw new Error('Refusing to serialize null value given as an object of quad');

				// array, list of objects
				if(Array.isArray(z_objects) || z_objects instanceof Set) {
					let s_write = '';

					// object terminator
					let s_term_object = '';

					// each object
					for(let z_item of z_objects) {
						// item is an array; write RDF collection
						if(Array.isArray(z_item)) {
							s_write += s_term_object + this.collection_object(z_item, n_nest_level);
						}
						// non-array
						else {
							// recurse on item
							s_write += s_term_object + this.objects(z_item, n_nest_level);
						}

						// terminate next object
						s_term_object = ', ';
					}

					return s_write;
				}
				// plain object, blank node
				else if(Object === z_objects.constructor) {
					// open blank node block
					let s_write = '[';

					// whether the block is empty
					let b_empty = true;

					// each pair
					for(let sc1_predicate in z_objects) {
						// block is not empty
						b_empty = false;

						// terminate previous pair
						s_write += '\n'+s_indent.repeat(2+n_nest_level);

						// directive; serialize it
						if('`' === sc1_predicate[0]) {
							s_write += this.directive(sc1_predicate, z_objects[sc1_predicate]);
							continue;
						}

						// write predicate and object(s)
						s_write += factory.c1(sc1_predicate, h_prefixes).terse(h_prefixes) + ' '
							+ this.objects(z_objects[sc1_predicate], n_nest_level+1) +' ;';
					}

					// close blank node block
					s_write += (b_empty? '': '\n'+s_indent.repeat(1+n_nest_level))+']';

					// serialize current predicate to blank node
					return s_write;
				}
				// coercable instance
				else if(hm_coercions.has(z_objects.constructor)) {
					// convert javascript object to term object
					let kt_converted = hm_coercions.get(z_objects.constructor).apply(this, [z_objects, n_nest_level]);

					// serialize
					return kt_converted.terse(h_prefixes);
				}
				// graphy term
				else if(z_objects.isGraphyTerm) {
					return z_objects.terse(h_prefixes);
				}
				// RDFJS term
				else if(z_objects.termType) {
					return factory.from.term(z_objects).terse(h_prefixes);
				}
			}

			// fallthrough: other
			default: {
				throw new Error(`Bad type for RDF object: [${typeof z_objects}] ${z_objects? z_objects.constructor: z_objects}`);
			}
		}
	}

	// serialize collection object
	collection_object(a_collection, n_nest_level) {
		let s_indent = this.indent;

		// open collection block
		let s_write = '(';

		// each item
		for(let z_item of a_collection) {
			let s_objects = '';

			// item is array; serialize as sub-collection
			if(Array.isArray(z_item)) {
				s_objects = this.collection_object(z_item, n_nest_level+1);
			}
			// non-array item
			else {
				s_objects = this.objects(z_item, n_nest_level+1);
			}

			// serialize collection
			s_write += '\n'+s_indent.repeat(2+n_nest_level)+s_objects;
		}

		// break line if anything was written (including comments)
		if(a_collection.length) s_write += '\n'+s_indent.repeat(1+n_nest_level);

		// close collection block
		s_write += ')';

		return s_write;
	}

	// rdfjs quad
	serialize_quad(g_quad) {
		let h_prefixes = this.prefixes;
		let kq_quad = factory.from.quad(g_quad);

		let st_graph = kq_quad.graph.terse(h_prefixes);

		// serialize quad
		let s_write = (2 !== this.state? '\n': '')
							+this.graph_token+(st_graph? st_graph+' ': '')+'{\n\t'
						+kq_quad.subject.terse(h_prefixes)+' '
			+kq_quad.predicate.terse(h_prefixes)+' '
			+kq_quad.object.terse(h_prefixes)+' .\n'
							+'}\n\n';


		// update state
		this.state = 2;

		return s_write;
	}
}

Object.assign(TriG_Writer.prototype, {
	anonymous_blank_nodes: true,
});

module.exports = function(gc_writer) {
	return new TriG_Writer(gc_writer);
};
