{"cells":[{"cell_type":"markdown","metadata":{"id":"rV3ck1wXJ3xL","pycharm":{"name":"#%% md\n"}},"source":["# Task 1: Using RLTK to perform Entity Resolution (ER)\n","\n","<sub>Content of this notebook was prepared by Basel Shbita, and modified by Avijit Thawani (thawani@usc.edu) as part of the class <u>DSCI 558: Building Knowledge Graphs</u> at University of Southern California (USC).</sub>"]},{"cell_type":"markdown","metadata":{"id":"vKYLgCLPJ3xN","pycharm":{"name":"#%% md\n"}},"source":["The Record Linkage ToolKit ([RLTK](https://github.com/usc-isi-i2/rltk)) is a general-purpose open-source record linkage platform that allows users to build powerful Python programs that link records referring to the same underlying entity.\n","\n","This notebook introduces some applied examples using RLTK. You can also find additional examples and use-cases in [RLTK's documentation](https://rltk.readthedocs.io/en/master/)."]},{"cell_type":"markdown","metadata":{"id":"z2Q5FfqkJ3xN","pycharm":{"name":"#%% md\n"}},"source":["## Dataset analysis & RLTK components construction"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"fTlKyPqCJ3xO","outputId":"f8d02d9d-601c-4c75-e48e-842d5dba3de7","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["# !pip install rltk"]},{"cell_type":"markdown","metadata":{"id":"K8fyiwzJJ3xP","pycharm":{"name":"#%% md\n"}},"source":["### Task 1-1. Construct RLTK Datasets\n","\n","First, you need define how a single entry would like for each type of record (for each dataset)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"We7cQGTRJ3xP","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import rltk\n","import csv\n","\n","# You can use this tokenizer in case you need to manipulate some data\n","tokenizer = rltk.tokenizer.crf_tokenizer.crf_tokenizer.CrfTokenizer()"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"T3Q_rPqmJ3xP","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["'''\n","Goodreads\n","    id: ID\n","    name_string: Title\n","    name_token: Title_Token\n","    author: FirstAuthor\n","    publisher: Publisher\n","\n","Nobel\n","    id: ID\n","    name_string: Title\n","    name_token: Title_Token\n","    author: Author1\n","    publisher: Publisher\n","\n","'''\n","\n","class GoodRecord(rltk.Record):\n","    def __init__(self, raw_object):\n","        super().__init__(raw_object)\n","        self.name = ''\n","\n","    @rltk.cached_property\n","    def id(self):\n","        return self.raw_object['ID']\n","\n","    @rltk.cached_property\n","    def name_string(self):\n","        return self.raw_object['Title']\n","\n","    @rltk.cached_property\n","    def author(self):\n","        return self.raw_object['FirstAuthor']\n","    \n","    @rltk.cached_property\n","    def authors(self):\n","        l = []\n","        if self.raw_object['FirstAuthor']:\n","            l.append(self.raw_object['FirstAuthor'])\n","        if self.raw_object['SecondAuthor']:\n","            l.append(self.raw_object['SecondAuthor'])\n","        if self.raw_object['ThirdAuthor']:\n","            l.append(self.raw_object['ThirdAuthor'])\n","        \n","        return l\n","\n","    @rltk.cached_property\n","    def ISBN(self):\n","        return self.raw_object['ISBN']\n","\n","    @rltk.cached_property\n","    def ISBN13(self):\n","        return self.raw_object['ISBN13']\n","    \n","    @rltk.cached_property\n","    def page_count(self):\n","        return self.raw_object['PageCount']\n","\n","    @rltk.cached_property\n","    def description(self):\n","        return self.raw_object['Description']\n","    \n","    @rltk.cached_property\n","    def rating(self):\n","        return self.raw_object['Rating']   \n","\n","    @rltk.cached_property\n","    def num_rating(self):\n","        return self.raw_object['NumberofRatings']   \n","\n","    @rltk.cached_property\n","    def num_review(self):\n","        return self.raw_object['NumberofReviews']   \n","\n","    @rltk.cached_property\n","    def publish_date(self):\n","        return self.raw_object['PublishDate']   \n","\n","    @rltk.cached_property\n","    def publish_format(self):\n","        return self.raw_object['Format']   \n","\n","    @rltk.cached_property\n","    def language(self):\n","        return self.raw_object['Language']   \n","\n","    @rltk.cached_property\n","    def publisher(self):\n","        return self.raw_object['Publisher']\n","\n","    @rltk.cached_property\n","    def name_tokens(self):\n","        return set(tokenizer.tokenize(self.name_string))\n","\n","class NobleRecord(rltk.Record):\n","    def __init__(self, raw_object):\n","        super().__init__(raw_object)\n","        self.name = ''\n","\n","    @rltk.cached_property\n","    def id(self):\n","        return self.raw_object['ID']\n","\n","    @rltk.cached_property\n","    def name_string(self):\n","        return self.raw_object['Title']\n","    \n","    @rltk.cached_property\n","    def date(self):\n","        return self.raw_object['PublicationDate']\n","\n","    @rltk.cached_property\n","    def author(self):\n","        return self.raw_object['Author1']\n","    \n","    @rltk.cached_property\n","    def publisher(self):\n","        return self.raw_object['Publisher']\n","    \n","    @rltk.cached_property\n","    def name_tokens(self):\n","        return set(tokenizer.tokenize(self.name_string))\n","\n","    @rltk.cached_property\n","    def dimension(self):\n","        return self.raw_object['Productdimensions']\n","    \n","\n","    @rltk.cached_property\n","    def sales_rank(self):\n","        return self.raw_object['Salesrank']\n","\n","    @rltk.cached_property\n","    def rating_count(self):\n","        return self.raw_object['Ratingscount']\n","\n","    @rltk.cached_property\n","    def paper_price(self):\n","        return self.raw_object['Paperbackprice']\n","\n","    @rltk.cached_property\n","    def hard_price(self):\n","        return self.raw_object['Hardcoverprice']\n","\n","    @rltk.cached_property\n","    def nook_price(self):\n","        return self.raw_object['Nookbookprice']\n","\n","    @rltk.cached_property\n","    def audio_price(self):\n","        return self.raw_object['Audiobookprice']\n","\n","    @rltk.cached_property\n","    def rating_value(self):\n","        return self.raw_object['Ratingvalue']"]},{"cell_type":"markdown","metadata":{"id":"4XHgnuhJJ3xQ","pycharm":{"name":"#%% md\n"}},"source":["You can load your csv files into RLTK using this method:"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"cZ2VHWnwJ3xQ","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["dir_ = ''\n","good_file = dir_ + 'goodreads.csv'\n","noble_file = dir_ + 'barnes_and_nobles.csv'\n","\n","ds1 = rltk.Dataset(rltk.CSVReader(good_file),record_class=GoodRecord)\n","ds2 = rltk.Dataset(rltk.CSVReader(noble_file),record_class=NobleRecord)"]},{"cell_type":"markdown","metadata":{"id":"KIylouixJ3xQ","pycharm":{"name":"#%% md\n"}},"source":["And we can inspect a few entries:"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"5CUrpjGTJ3xQ","outputId":"498d3b0e-a742-4740-8751-3a348661e5d0","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["  id                                        name_string        date  \\\n","0  0          Pioneer Girl: The Annotated Autobiography  12/12/2014   \n","1  1  American Sniper (Movie Tie-in Edition): The Au...  11/25/2014   \n","2  2                     The Autobiography of Malcolm X  10/28/1987   \n","3  3                           Assata: An Autobiography  11/28/1999   \n","4  4                            Autobiography of a Yogi  12/28/1978   \n","\n","                  author                              publisher  \\\n","0   Laura Ingalls Wilder  South Dakota State Historical Society   \n","1             Chris Kyle               HarperCollins Publishers   \n","2              Malcolm X          Random House Publishing Group   \n","3          Assata Shakur     Chicago Review Press, Incorporated   \n","4  Paramahansa Yogananda            Self-Realization Fellowship   \n","\n","                                         name_tokens  \\\n","0  {Annotated, Autobiography, :, Pioneer, Girl, The}   \n","1  {Edition, -, History, in, U, :, Tie, Military,...   \n","2               {of, X, Autobiography, The, Malcolm}   \n","3                     {:, Assata, Autobiography, An}   \n","4                       {a, of, Yogi, Autobiography}   \n","\n","                      dimension sales_rank rating_count paper_price  \\\n","0  9.50(w) x 10.10(h) x 1.50(d)         68           16               \n","1   5.20(w) x 7.90(h) x 1.40(d)        734         1037      $12.69   \n","2   4.20(w) x 6.80(h) x 1.10(d)     15,276          140       $7.99   \n","3   6.00(w) x 9.00(h) x 0.85(d)     33,315           26      $13.26   \n","4   7.52(w) x 4.62(h) x 1.02(d)     36,103           26       $8.50   \n","\n","  hard_price nook_price audio_price rating_value  \n","0     $32.03                                 3.7  \n","1     $19.61      $7.99      $21.98          4.3  \n","2     $23.52      $7.99                      4.5  \n","3                                            4.7  \n","4     $23.40      $4.99      $45.44          4.3  \n"]}],"source":["# print some entries\n","#print(ds1.generate_dataframe().head(5))\n","print(ds2.generate_dataframe().head(5))"]},{"cell_type":"markdown","metadata":{"id":"MB0HHqDpJ3xR"},"source":["### Task 1-2. Blocking\n","\n","First, we'll load dev set to evaluate both blocking (Task 1-2) and entity linking (Task 1-3)."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YfGah0DhJ3xR","outputId":"762cc35a-df00-46f4-fb8f-0200a600bd71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Column names are: goodreads.ID, barnes_and_nobles.ID, label\n","Processed 297 lines.\n"]},{"data":{"text/plain":["<rltk.evaluation.trial.Trial at 0x7fb2af348a60>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dev_set_file = dir_ + 'dev.csv'\n","dev = []\n","with open(dev_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","    line_count = 0\n","    for row in csv_reader:\n","        if len(row) <= 1:\n","            continue\n","        if line_count == 0:\n","            columns = row\n","            line_count += 1\n","        else:\n","            dev.append(row)\n","    print(f'Column names are: {\", \".join(columns)}')\n","    print(f'Processed {len(dev)} lines.')\n","\n","gt = rltk.GroundTruth()\n","for row in dev:    \n","    r1 = ds1.get_record(row[0])\n","    r2  = ds2.get_record(row[1])\n","    if row[-1] == '1':\n","        gt.add_positive(r1.raw_object['ID'], r2.raw_object['ID'])\n","    else:\n","        gt.add_negative(r1.raw_object['ID'], r2.raw_object['ID'])\n","\n","rltk.Trial(gt)"]},{"cell_type":"markdown","metadata":{"id":"aJ07ud86J3xR"},"source":["Then, you can build your own blocking techniques and evaluate it.\n","\n","Hint:\n","\n","- What is the total number of pairs without blocking? \n","- what is the number of paris with blocking?\n","- After blocking, how many \"correct\" (matched) pairs presented in dev set?\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def reduction_ratio(ds1, ds2, block):\n","    \"\"\"\n","    Calculate reduction ratio based on two original datasets and the final blocks\n","    \"\"\"\n","    block_pairs = len(list(rltk.get_record_pairs(ds1, ds2, block=block)))\n","\n","    ds1_size = len(ds1.generate_dataframe())\n","    ds2_size = len(ds2.generate_dataframe())\n","\n","    ratio = float((block_pairs) / (ds1_size * ds2_size))\n","\n","    print('Total pairs before blocking: %s', ds1_size * ds2_size)\n","    print('Pairs after blocking: %s', block_pairs)\n","    print('Reduction Ratio: %s', ratio)\n","    return ratio"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--- block on author ---\n","('Alex Ferguson', {('NobleRecord', '53'), ('GoodRecord', '0')})\n","('Boris Pasternak', {('GoodRecord', '3418'), ('GoodRecord', '261'), ('GoodRecord', '1'), ('NobleRecord', '3459'), ('NobleRecord', '1083')})\n","('Betty Boothroyd', {('NobleRecord', '2541'), ('GoodRecord', '158'), ('GoodRecord', '2')})\n","('Caddie', {('GoodRecord', '3')})\n","('Rudolf Nureyev', {('GoodRecord', '4')})\n","----------------------\n","Total pairs before blocking: %s 14681867\n","Pairs after blocking: %s 2933\n","Reduction Ratio: %s 0.0001997702335813286\n"]},{"data":{"text/plain":["0.0001997702335813286"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["print('--- block on author ---')\n","bg = rltk.HashBlockGenerator()\n","block = bg.generate(bg.block(ds1, property_='author'),\n","                    bg.block(ds2, property_='author'))\n","\n","for idx, b in enumerate(block.key_set_adapter):\n","    if idx == 5: break\n","    print(b)\n","\n","print('----------------------')\n","\n","reduction_ratio(ds1, ds2, block)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["\"\\nprint('--- block on publisher ---')\\nbg = rltk.HashBlockGenerator()\\nblock2 = bg.generate(bg.block(ds1, property_='publisher'),\\n                    bg.block(ds2, property_='publisher'))\\n\\nfor idx, b in enumerate(block2.key_set_adapter):\\n    if idx == 5: break\\n    print(b)\\n\\nprint('----------------------')\\n\\nreduction_ratio(ds1, ds2, block2)\\n\""]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","print('--- block on publisher ---')\n","bg = rltk.HashBlockGenerator()\n","block2 = bg.generate(bg.block(ds1, property_='publisher'),\n","                    bg.block(ds2, property_='publisher'))\n","\n","for idx, b in enumerate(block2.key_set_adapter):\n","    if idx == 5: break\n","    print(b)\n","\n","print('----------------------')\n","\n","reduction_ratio(ds1, ds2, block2)\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["#### Pairwise comparison"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def pairs_completeness_and_quality(ds1, ds2, block, gt):\n","    \"\"\"\n","    Calculate pairs completeness and quality using the block & groundtruth provided\n","\n","    Returns (completeness, quality)\n","    \"\"\"\n","\n","    groundtruth = {}\n","    true_matches_compared = 0\n","    matches_compared = 0\n","\n","    for id1, id2, label in gt:\n","        if label == 1:\n","            groundtruth[id1] = id2\n","    total_true_matches = len(groundtruth)\n","\n","    for key, id1, id2 in block.pairwise(ds1, ds2):\n","        matches_compared += 1\n","        if id1 in groundtruth and groundtruth[id1] == id2:\n","            true_matches_compared += 1\n","\n","    # Recall\n","    completeness = float(true_matches_compared) / total_true_matches\n","    print('Pairs Completeness = %s / %s  = %s' %(true_matches_compared, total_true_matches, completeness))\n","\n","    # Precision\n","    quality = float(true_matches_compared) / matches_compared\n","    print('Pairs quality = %s / %s = %s' %(true_matches_compared, matches_compared, quality))\n","\n","    return (completeness, quality)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Pairs Completeness = 53 / 67  = 0.7910447761194029\n","Pairs quality = 53 / 2933 = 0.018070235254006136\n"]}],"source":["# Evaluate blocking with author name\n","(_,_) = pairs_completeness_and_quality(ds1, ds2, block, gt)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Evaluate blocking with publisher\n","# (_,_) = pairs_completeness_and_quality(ds1, ds2, block2, gt)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Write blocked pairs to CSV\n","import csv\n","\n","with open('Rui_Zhu_blocked.csv', 'wt', newline ='') as file:\n","    writer = csv.writer(file, delimiter=',')\n","    writer.writerow([\"goodreads.ID\", \"barnes_and_nobles.ID\"])\n","    for key, id1, id2 in block.pairwise(ds1, ds2):\n","        writer.writerow((id1, id2))"]},{"cell_type":"markdown","metadata":{"id":"OCpi3AqZJ3xR","pycharm":{"name":"#%% md\n"}},"source":["### Task 1-3. Entity Linking"]},{"cell_type":"markdown","metadata":{"id":"98xt8o9kJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Here are 2 example functions for field (attribute) similarity:"]},{"cell_type":"markdown","metadata":{"id":"9peeajHNJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Here's how you can combine multiple similarity functions into a single weightened scoring function:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"fGf52bBcJ3xS","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["# threshold value to determine if we are confident the record match\n","MY_TRESH = 0.7 # this number is just an example, you need to change it\n","\n","def title_similarity_1(r1, r2):\n","    s1 = r1.name_string\n","    s2 = r2.name_string\n","    \n","    return rltk.jaro_winkler_similarity(s1, s2)\n","    \n","def title_similarity_2(r1, r2):\n","    s1 = r1.name_string\n","    s2 = r2.name_string\n","    \n","    if s1 == s2:\n","        return 1\n","    \n","    return 0\n","\n","def author_similarity_1(r1, r2):\n","    s1 = r1.author\n","    s2 = r2.author\n","    \n","    return rltk.jaro_winkler_similarity(s1, s2)\n","    \n","def author_similarity_2(r1, r2):\n","    s1 = r1.author\n","    s2 = r2.author\n","    \n","    if s1 == s2:\n","        return 1\n","    \n","    return 0\n","\n","def publisher_similarity_1(r1, r2):\n","    s1 = r1.publisher\n","    s2 = r2.publisher\n","    \n","    return rltk.jaro_winkler_similarity(s1, s2)\n","    \n","def publisher_similarity_2(r1, r2):\n","    ''' Example dummy similarity function '''\n","    s1 = r1.publisher\n","    s2 = r2.publisher\n","    \n","    if s1 == s2:\n","        return 1\n","    \n","    return 0\n","\n","\n","\n","# entity linkage scoring function\n","def rule_based_method(r1, r2, A, B, C, D):\n","    author_similar = author_similarity_1(r1, r2)\n","    author_exact = author_similarity_2(r1, r2)\n","    title_similar = title_similarity_1(r1, r2)\n","    title_exact = title_similarity_2(r1, r2)\n","    publisher_similar = publisher_similarity_1(r1, r2)\n","    publisher_exact = publisher_similarity_2(r1, r2)\n","    \n","    total = A * title_similar + B * title_exact + C * author_exact + D * publisher_exact\n","    \n","    # return two values: boolean if they match or not, float to determine confidence\n","    return total > MY_TRESH, total"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Xo9-fdimJ3xS","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------\n","Total pair compared: 297\n","Trial statistics based on Ground-Truth from development set data:\n","tp: 0.895522 [60]\n","fp: 0.152174 [35]\n","tn: 0.847826 [195]\n","fn: 0.104478 [7]\n","---------------\n","F-score: 0.7407407407407407\n"]}],"source":["count = 0\n","\n","trial = rltk.Trial(gt)\n","candidate_pairs = rltk.get_record_pairs(ds1, ds2, ground_truth=gt)\n","for r1, r2 in candidate_pairs:\n","    count += 1\n","    result, confidence = rule_based_method(r1, r2, A=0.67, B=0.13, C=0.1, D=0.1)\n","    trial.add_result(r1, r2, result, confidence)\n","\n","print('---------------')\n","print('Total pair compared: %s' % count)\n","trial.evaluate()\n","print('Trial statistics based on Ground-Truth from development set data:')\n","print(f'tp: {trial.true_positives:.06f} [{len(trial.true_positives_list)}]')\n","print(f'fp: {trial.false_positives:.06f} [{len(trial.false_positives_list)}]')\n","print(f'tn: {trial.true_negatives:.06f} [{len(trial.true_negatives_list)}]')\n","print(f'fn: {trial.false_negatives:.06f} [{len(trial.false_negatives_list)}]')\n","\n","print('---------------')\n","print('F-score: %s' % trial.f_measure)"]},{"cell_type":"markdown","metadata":{"id":"tqhybHyKJ3xS","pycharm":{"name":"#%% md\n"}},"source":["Now lets evaluate our trial results"]},{"cell_type":"markdown","metadata":{"id":"32c-kCWqJ3xT","pycharm":{"name":"#%% md\n"}},"source":["### Save Test predictions\n","You will be evaluated on dev and test predictions, over a hidden ground truth."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"t1qkfFDrJ3xT","outputId":"8bed2f96-0065-4893-e9ac-21d8e44ced53","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Column names are: goodreads.ID, barnes_and_nobles.ID\n","Processed 90 lines.\n"]}],"source":["test_set_file = dir_ + 'test.csv'\n","test = []\n","with open(test_set_file, encoding='utf-8', errors=\"replace\") as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","    line_count = 0\n","    for row in csv_reader:\n","        if len(row) <= 1:\n","            continue\n","        if line_count == 0:\n","            columns = row\n","            line_count += 1\n","        else:\n","            test.append(row)\n","    print(f'Column names are: {\", \".join(columns)}')\n","    print(f'Processed {len(test)} lines.')"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"UfC2TKISJ3xT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["predictions = []\n","for id1, id2 in test:\n","    r1 = ds1.get_record(id1)\n","    r2  = ds2.get_record(id2)\n","    result, confidence = rule_based_method(r1, r2, A=0.67, B=0.13, C=0.1, D=0.1)\n","    predictions.append((r1.id, r2.id, result, confidence))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"4UCWB2Q6J3xT","outputId":"5a2d2a1d-3c4a-4d87-da59-89cc94ee6f8b","pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/plain":["(90, 3967, 3701)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(predictions), len(ds1.generate_dataframe()), len(ds2.generate_dataframe())"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"UnxUzg4WJ3xT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["with open(dir_ + 'Rui_Zhu_predictions.csv', mode='w') as file:\n","    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    writer.writerow([\"goodreads.ID\", \"barnes_and_nobles.ID\", \"prediction\", \"confidence\"])\n","    for row in predictions:\n","        writer.writerow(row)"]},{"cell_type":"markdown","metadata":{},"source":["### Task 1.4 (2 pts) - Record Linkage"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total: 2933\n","valid: 1147\n"]}],"source":["total = 0\n","count = 0\n","\n","with open(dir_ + 'Rui_Zhu_valid_predictions.csv', mode='w') as file:\n","    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    writer.writerow([\"goodreads.ID\", \"barnes_and_nobles.ID\"])\n","\n","    block_pairs = list(rltk.get_record_pairs(ds1, ds2, block=block))\n","    for r1, r2 in block_pairs:\n","        total += 1\n","        result, confidence = rule_based_method(r1, r2, A=0.67, B=0.13, C=0.1, D=0.1)\n","        if result==1:\n","            count += 1\n","            #writer.writerow((r1.id, r2.id, confidence))\n","            writer.writerow((r1.id, r2.id))\n","\n","\n","print(\"Total: \" + str(total))\n","print(\"valid: \" + str(count))"]},{"cell_type":"markdown","metadata":{"id":"G7svOwNGJ3xT","pycharm":{"name":"#%% md\n"}},"source":["# Task 2: Using RDFLib for Knowledge Representation"]},{"cell_type":"markdown","metadata":{"id":"RDtcKE-kJ3xT","pycharm":{"name":"#%% md\n"}},"source":["RDFLib is a Python library for working with RDF, a simple yet powerful language for representing information as graphs. RDFLib aims to be a pythonic RDF API, a Graph is a python collection of RDF Subject, Predicate,  Object Triples.\n","\n","This notebook introduces simple examples. You can also find additional information in the [official documenation](https://rdflib.readthedocs.io/en/stable/)."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"yQmhRDzUJ3xT","outputId":"488a0cab-2e34-4798-d316-57733f682733","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rdflib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (6.2.0)\n","Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from rdflib) (49.2.1)\n","Requirement already satisfied: isodate in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from rdflib) (0.6.1)\n","Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from rdflib) (3.0.6)\n","Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from isodate->rdflib) (1.16.0)\n","\u001b[33mWARNING: You are using pip version 21.3; however, version 22.2.2 is available.\n","You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["! pip install rdflib"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"XSlFv0BhJ3xT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF"]},{"cell_type":"markdown","metadata":{"id":"M-loxb1-J3xU","pycharm":{"name":"#%% md\n"}},"source":["Let's define some namespaces:"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"z0SzNXOhJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["FOAF = Namespace('http://xmlns.com/foaf/0.1/')\n","MYNS = Namespace('http://dsci558.org/myfakenamespace#')"]},{"cell_type":"markdown","metadata":{"id":"k7Rul4D1J3xU","pycharm":{"name":"#%% md\n"}},"source":["We can create a graph:"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"rSQH4Uo5J3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["my_kg = Graph()\n","my_kg.bind('myns', MYNS)\n","my_kg.bind('foaf', FOAF)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["import csv\n","\n","final_pairs = []\n","\n","with open(\"Rui_Zhu_valid_predictions.csv\", \"r\") as f:\n","    reader = csv.reader(f, delimiter=\"\\t\")\n","    for i, line in enumerate(reader):\n","        if i == 0: \n","            continue\n","        final_pairs.append(line[0].split(','))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["[['3418', '1083'], ['2', '2541'], ['8', '1431'], ['11', '100'], ['13', '1152']]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["final_pairs[:5]"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["# DS1: Goodread\n","\n","for pair in final_pairs:\n","    id1 = pair[0]\n","    id2 = pair[1]\n","\n","    r1 = ds1.get_record(id1)\n","    r2 = ds2.get_record(id2)\n","\n","    title = r1.name_string\n","    description = r1.description\n","    isbn = r1.ISBN\n","    isbn13 = r1.ISBN13\n","    page_count= r1.page_count\n","    authors= r1.authors\n","    rating = r1.rating\n","    num_rating = r1.num_rating\n","    num_review = r1.num_review\n","    publisher = r1.publisher\n","    publish_date= r1.publish_date\n","    publish_format = r1.publish_format\n","    language= r1.language\n","\n","    dim = r2.dimension\n","    sale_rank = r2.sales_rank\n","    rating_count = r2.rating_count\n","    paper_price = r2.paper_price\n","    hard_price = r2.hard_price\n","    nook_price = r2.nook_price\n","    audio_price =r2.audio_price\n","    rating_value = r2.rating_value\n","\n","    node_uri = URIRef(MYNS[id1])\n","    my_kg.add((node_uri, RDF.type, MYNS['book']))\n","    my_kg.add((node_uri, MYNS['title'], Literal(title)))\n","    my_kg.add((node_uri, MYNS['description'], Literal(description)))\n","    my_kg.add((node_uri, MYNS['isbn_id'], Literal(isbn)))\n","    my_kg.add((node_uri, MYNS['isbn13_id'], Literal(isbn13)))\n","    my_kg.add((node_uri, MYNS['page_count'], Literal(page_count)))\n","    my_kg.add((node_uri, FOAF['Person'], Literal(authors)))\n","    my_kg.add((node_uri, MYNS['rate'], Literal(rating)))\n","    my_kg.add((node_uri, MYNS['rate_count'], Literal(num_rating)))\n","    my_kg.add((node_uri, MYNS['rate_count'], Literal(num_review)))\n","    my_kg.add((node_uri, FOAF['Group'], Literal(publisher)))\n","    my_kg.add((node_uri, MYNS['publish_date'], Literal(publish_date)))\n","    my_kg.add((node_uri, MYNS['format'], Literal(publish_format)))\n","    my_kg.add((node_uri, MYNS['language'], Literal(language)))\n","\n","    my_kg.add((node_uri, MYNS['dimension'], Literal(dim)))\n","    my_kg.add((node_uri, MYNS['rate'], Literal(sale_rank)))\n","    my_kg.add((node_uri, MYNS['rate_count'], Literal(rating_count)))\n","    my_kg.add((node_uri, MYNS['price'], Literal(paper_price)))\n","    my_kg.add((node_uri, MYNS['price'], Literal(hard_price)))\n","    my_kg.add((node_uri, MYNS['price'], Literal(nook_price)))\n","    my_kg.add((node_uri, MYNS['price'], Literal(audio_price)))\n","    my_kg.add((node_uri, MYNS['rate'], Literal(rating_value)))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wAY1RbdIJ3xU","pycharm":{"name":"#%% md\n"}},"source":["Define a URI, then add a simple triple to the graph:"]},{"cell_type":"markdown","metadata":{"id":"oof8rvbjJ3xU","pycharm":{"name":"#%% md\n"}},"source":["Add an additional triple (which describes the same subject, `node_uri`):"]},{"cell_type":"markdown","metadata":{"id":"ed_XbkFbJ3xU","pycharm":{"name":"#%% md\n"}},"source":["And now let's dump our graph triples into some `ttl` file:"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"n2MI9-KKJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[{"data":{"text/plain":["<Graph identifier=N1af025d3c1df4bdcbec840bbb5f7aa27 (<class 'rdflib.graph.Graph'>)>"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["my_kg.serialize(dir_ + 'Rui_Zhu_model.ttl', format=\"turtle\")"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"NIfJgmAvJ3xU","outputId":"f243c52a-40d9-4950-f45e-cc7fbbe0e22e","pycharm":{"name":"#%%\n"}},"outputs":[{"name":"stdout","output_type":"stream","text":["@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n","@prefix myns: <http://dsci558.org/myfakenamespace#> .\n","\n","myns:100 a myns:book ;\n","    myns:description \" \" ;\n","    myns:dimension \" \" ;\n","    myns:format \"Paperback\" ;\n","    myns:isbn13_id \"9780688109646\" ;\n","    myns:isbn_id \"0688109640\" ;\n","    myns:language \"English\" ;\n"]}],"source":["!head Rui_Zhu_model.ttl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvnuzp4OJ3xU","pycharm":{"name":"#%%\n"}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.8.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"vscode":{"interpreter":{"hash":"949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"}}},"nbformat":4,"nbformat_minor":0}
